{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17604d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pathways\\AppData\\Local\\Temp\\ipykernel_11208\\1328076593.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Status'] = df_filtered.apply(check_day_differences, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, COUNTRY, PRODUCTBASECURRENCY, POLICYHOLDERNAME, POLICYID, MAINPOLICYID, POLICYSTATUS, POLICYSTARTDATE, RENEWALDATE, ENDDATE, BENEFICIARYID, BENEFICIARYNAME, ParentBeneficiary, UNIQUE_CLAIMS, INVOICEBENEFIT, INVOICEBENEFIT_DESCRIPTION, BENEFIT, INVOICELINEDETAILS, INVOICEID, ORIGINALINVOICEGROSSAMOUNT, RECOVEREDAMOUNT, RECOVERYDISCOUNTPBC, NHIFAMOUNTPBC, INVLINEPBCDISCOUNTAMOUNT, INVLINEPBCDENIEDAMOUNT, BENEFITEXCESSAPPLIED, INVOICEAMOUNT, INVOICEDAMOUNT, SETTLEDAMOUNT, INVOICELINEUSERSTATUS, PAYMENT_AMOUNT, PRODUCT, INVOICELINESTATUS, INVOICESTATUS, Claims_Invoice_Status, Claim_Decline_Status, INVOICECURRENCYDENIEDAMOUNT, INVOICEREFERENCE, ASSESSMENTID, DOB, TREATMENTID, YR, ASSESSEDDATE, CAPTUREDBY, ASSESSEDBY, REASONCODEDESC, CREDITREASONDESC, ReasonText, INVOICEACCOUNTNAME, INVOICEENTITYNAME, INVOICEENTITY, ADMISSIONDATE, FIRSTDIAGNOSIS, SECONDDIAGNOSIS, ICD10, DELIVERYCATEGORY, PAYEE, ENTITYID, CHEQUENUMBER, PAYMENTDATE, PAYMENTSTATUSDESC, RISKGROUPDESC, INVOICELINESUBBENEFIT, CATEGORYNAME, RELATIONSHIP, CHARGECATEGORY, QA_COMMENTS, AUTHENTICATION_TYPE, INVOICEFROM, INVOICEFROMNAME, CURACEL_DECLINE_REASON, CURACEL_STATUS, CURACEL_AMOUNT, InvoiceLineId, BatchClaimId, BatchClaimReference, InvoiceRef, TREATMENTDATE, RECEIVEDDATE, CAPTUREDATE, DISCHARGEDATE, INVOICEDATE, EFFECTIVEDATE, Prescribed Amount, Prescription, Variance, Log_INVOICEDAMOUNT, Log_Prescribed_Amount, PRESCRIBEDAMOUNT, Prescription_Status, Days_Treatment, Days_Received, Days_Discharge, Days_Invoice, Status]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Load datasets from CSV files with low_memory=False to prevent dtype warnings\n",
    "df_new = pd.read_csv('new_data.csv', low_memory=False)\n",
    "historical_data = pd.read_csv('historical_data.csv', low_memory=False)\n",
    "\n",
    "# Function to extract text between the last two commas\n",
    "def extract_prescription(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        parts = text.rsplit(',', 2)\n",
    "        if len(parts) > 1:\n",
    "            return parts[-2].strip()\n",
    "    return ''  # Default to empty string if not a string or insufficient parts\n",
    "\n",
    "# Function to extract prescription names\n",
    "def extract_prescription_name(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'^(.*?)\\s*\\(', text)  # Matches text before the first parenthesis\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned prescription name\n",
    "    return None  # Return None for invalid input\n",
    "\n",
    "# Apply extraction functions to both datasets\n",
    "for df in [historical_data, df_new]:\n",
    "    if 'ReasonText' in df.columns:\n",
    "        df['Prescription'] = df['ReasonText'].apply(extract_prescription)\n",
    "        df['Prescription Name'] = df['Prescription'].apply(extract_prescription_name)\n",
    "        df['Prescription'] = df['Prescription Name']\n",
    "        df.drop(columns=['Prescription Name'], inplace=True)\n",
    "\n",
    "# Function to extract prescribed amount\n",
    "def extract_prescribed_amount(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'=(.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned amount\n",
    "    return None  # Default to None for invalid input\n",
    "\n",
    "# Extract prescribed amounts\n",
    "if 'ReasonText' in df_new.columns:\n",
    "    df_new['Prescribed Amount'] = df_new['ReasonText'].apply(extract_prescribed_amount)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "date_columns = ['CAPTUREDATE', 'TREATMENTDATE', 'RECEIVEDDATE', 'DISCHARGEDATE', 'INVOICEDATE']\n",
    "for col in date_columns:\n",
    "    if col in df_new.columns:\n",
    "        df_new[col] = pd.to_datetime(df_new[col], errors='coerce')\n",
    "\n",
    "# Calculate day differences\n",
    "df_new['Days_Treatment'] = (df_new['TREATMENTDATE'] - df_new['CAPTUREDATE']).dt.days\n",
    "df_new['Days_Received'] = (df_new['RECEIVEDDATE'] - df_new['CAPTUREDATE']).dt.days\n",
    "df_new['Days_Discharge'] = (df_new['DISCHARGEDATE'] - df_new['CAPTUREDATE']).dt.days\n",
    "df_new['Days_Invoice'] = (df_new['INVOICEDATE'] - df_new['CAPTUREDATE']).dt.days\n",
    "\n",
    "# Filter based on INVOICELINEUSERSTATUS\n",
    "if 'INVOICELINEUSERSTATUS' in df_new.columns:\n",
    "    df_filtered = df_new[df_new['INVOICELINEUSERSTATUS'].isin(['Paid', 'NP - Not to be Paid'])]\n",
    "else:\n",
    "    df_filtered = df_new.copy()\n",
    "\n",
    "# Check for positive day differences\n",
    "def check_day_differences(row):\n",
    "    if any(day > 0 for day in [row['Days_Treatment'], row['Days_Received'], row['Days_Discharge'], row['Days_Invoice']]):\n",
    "        return \"decline\"\n",
    "    return \"proceed\"\n",
    "\n",
    "df_filtered['Status'] = df_filtered.apply(check_day_differences, axis=1)\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Check POLICYSTATUS\n",
    "if 'POLICYSTATUS' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['POLICYSTATUS'].apply(lambda x: \"proceed\" if x == \"Live\" else \"decline\")\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Check AUTHENTICATION_TYPE\n",
    "def check_authentication(auth_type):\n",
    "    if auth_type in [\"Blank\", \"UNAUTHORISED\", \"Off Smart\"]:\n",
    "        return \"decline\"\n",
    "    return \"proceed\"\n",
    "\n",
    "if 'AUTHENTICATION_TYPE' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['AUTHENTICATION_TYPE'].apply(check_authentication)\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Create a dictionary for historical prescriptions\n",
    "historical_dict = defaultdict(list)\n",
    "if 'FIRSTDIAGNOSIS' in historical_data.columns and 'Prescription' in historical_data.columns:\n",
    "    for diagnosis, prescription in zip(historical_data['FIRSTDIAGNOSIS'], historical_data['Prescription']):\n",
    "        historical_dict[diagnosis].append(prescription)\n",
    "\n",
    "# Function to check prescription match\n",
    "def check_diagnosis_and_prescription(row, historical_dict, threshold=80):\n",
    "    diagnosis = row['FIRSTDIAGNOSIS']\n",
    "    prescription = row['Prescription']\n",
    "    if diagnosis in historical_dict:\n",
    "        max_match_score = max(\n",
    "            (fuzz.ratio(prescription, hist_prescription) for hist_prescription in historical_dict[diagnosis]),\n",
    "            default=0,\n",
    "        )\n",
    "        return \"proceed\" if max_match_score >= threshold else \"decline\"\n",
    "    return \"new diagnosis\"\n",
    "\n",
    "df_filtered['Status'] = df_filtered.apply(\n",
    "    lambda row: check_diagnosis_and_prescription(row, historical_dict), axis=1\n",
    ")\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Check if Prescribed Amount matches INVOICEDAMOUNT\n",
    "if 'Prescribed Amount' in df_filtered.columns and 'INVOICEDAMOUNT' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered.apply(\n",
    "        lambda row: \"decline\" if row['Prescribed Amount'] != row['INVOICEDAMOUNT'] else \"proceed\", axis=1\n",
    "    )\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_data_set.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b883178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20278ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec4a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b50d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c719f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088901a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554dfc68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e81216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5075db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d055ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Load datasets from CSV files with low_memory=False to prevent dtype warnings\n",
    "df_new = pd.read_csv('new_data.csv', low_memory=False)\n",
    "historical_data = pd.read_csv('historical_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "901a4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For historical data: keep only 'FIRSTDIAGNOSIS' and 'ReasonText', drop nulls\n",
    "historical_data = historical_data[['FIRSTDIAGNOSIS', 'ReasonText']].dropna()\n",
    "\n",
    "# For df_new: keep only the specified columns\n",
    "df_new = df_new[['AUTHENTICATION_TYPE', 'POLICYSTATUS', 'FIRSTDIAGNOSIS', 'ReasonText', 'INVOICEDAMOUNT']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbe7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text between the last two commas\n",
    "def extract_prescription(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        parts = text.rsplit(',', 2)\n",
    "        if len(parts) > 1:\n",
    "            return parts[-2].strip()\n",
    "    return ''  # Default to empty string if not a string or insufficient parts\n",
    "\n",
    "# Function to extract prescription names\n",
    "def extract_prescription_name(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'^(.*?)\\s*\\(', text)  # Matches text before the first parenthesis\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned prescription name\n",
    "    return None  # Return None for invalid input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9345b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply extraction functions to both datasets\n",
    "for df in [historical_data, df_new]:\n",
    "    if 'ReasonText' in df.columns:\n",
    "        df['Prescription'] = df['ReasonText'].apply(extract_prescription)\n",
    "        df['Prescription Name'] = df['Prescription'].apply(extract_prescription_name)\n",
    "        df['Prescription'] = df['Prescription Name']\n",
    "        df.drop(columns=['Prescription Name'], inplace=True)\n",
    "\n",
    "# Function to extract prescribed amount\n",
    "def extract_prescribed_amount(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'=(.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned amount\n",
    "    return None  # Default to None for invalid input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebd7d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls with the mode for each column\n",
    "historical_data = historical_data.apply(lambda col: col.fillna(col.mode()[0]), axis=0)\n",
    "# Fill object columns with the mode\n",
    "df_new = df_new.apply(\n",
    "    lambda col: col.fillna(col.mode()[0]) if col.dtype == 'object' else col, axis=0\n",
    ")\n",
    "\n",
    "# Fill the INVOICEDAMOUNT column with the mean\n",
    "if 'INVOICEDAMOUNT' in df_new.columns:\n",
    "    df_new['INVOICEDAMOUNT'] = df_new['INVOICEDAMOUNT'].fillna(df_new['INVOICEDAMOUNT'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8c2e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 245564 entries, 0 to 245563\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   AUTHENTICATION_TYPE  245564 non-null  object \n",
      " 1   POLICYSTATUS         245564 non-null  object \n",
      " 2   FIRSTDIAGNOSIS       245564 non-null  object \n",
      " 3   ReasonText           245564 non-null  object \n",
      " 4   INVOICEDAMOUNT       245564 non-null  float64\n",
      " 5   Prescription         245564 non-null  object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfdf73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 984151 entries, 0 to 1038132\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   FIRSTDIAGNOSIS  984151 non-null  object\n",
      " 1   ReasonText      984151 non-null  object\n",
      " 2   Prescription    984151 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 30.0+ MB\n"
     ]
    }
   ],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28886eee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_new\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 5: Filter rows that are marked as \"proceed\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_filtered[df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproceed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Step 6: Check POLICYSTATUS\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLICYSTATUS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproceed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Status'"
     ]
    }
   ],
   "source": [
    "# Step 3: Filter based on INVOICELINEUSERSTATUS\n",
    "df_filtered = df_new\n",
    "\n",
    "# Step 5: Filter rows that are marked as \"proceed\"\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Step 6: Check POLICYSTATUS\n",
    "df_filtered['Status'] = df_filtered['POLICYSTATUS'].apply(lambda x: \"proceed\" if x == \"Live\" else \"decline\")\n",
    "\n",
    "# Step 7: Filter rows that are marked as \"proceed\"\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Step 8: Check AUTHENTICATION_TYPE\n",
    "def check_authentication(auth_type):\n",
    "    if auth_type in [\"Blank\", \"UNAUTHORISED\", \"Off Smart\"]:\n",
    "        return \"decline\"\n",
    "    return \"proceed\"\n",
    "\n",
    "df_filtered['Status'] = df_filtered['AUTHENTICATION_TYPE'].apply(check_authentication)\n",
    "\n",
    "# Step 9: Filter rows that are marked as \"proceed\"\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Step 10: Check Prescription against historical data\n",
    "# Assuming df_clean contains historical data with columns FIRSTDIAGNOSIS and Prescription\n",
    "historical_data = df_clean[['FIRSTDIAGNOSIS', 'Prescription']]  # historical data from df_clean\n",
    "historical_dict = defaultdict(list)\n",
    "\n",
    "# Populate historical dictionary with diagnosis and prescriptions\n",
    "for diagnosis, prescription in zip(historical_data['FIRSTDIAGNOSIS'], historical_data['Prescription']):\n",
    "    historical_dict[diagnosis].append(prescription)\n",
    "\n",
    "# Function to check if diagnosis and prescription match using fuzzy logic\n",
    "def check_diagnosis_and_prescription(row, historical_dict, threshold=80):\n",
    "    diagnosis = row['FIRSTDIAGNOSIS']\n",
    "    prescription = row['Prescription']\n",
    "    \n",
    "    # Check if diagnosis exists in historical data\n",
    "    if diagnosis in historical_dict:\n",
    "        historical_prescriptions = historical_dict[diagnosis]\n",
    "        max_match_score = 0  # Initialize highest match score\n",
    "        \n",
    "        # Compare with historical prescriptions\n",
    "        for historical_prescription in historical_prescriptions:\n",
    "            match_score = fuzz.ratio(prescription, historical_prescription)\n",
    "            if match_score > max_match_score:\n",
    "                max_match_score = match_score\n",
    "        \n",
    "        # If match score exceeds threshold, proceed, otherwise decline\n",
    "        if max_match_score >= threshold:\n",
    "            return \"proceed\"\n",
    "        else:\n",
    "            return \"decline\"\n",
    "    return \"new diagnosis\"  # If diagnosis not found\n",
    "\n",
    "# Apply function to check prescription match\n",
    "df_filtered['Status'] = df_filtered.apply(lambda row: check_diagnosis_and_prescription(row, historical_dict), axis=1)\n",
    "\n",
    "# Step 11: Filter for final rows where status is \"proceed\"\n",
    "df_final = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Step 12: Check if Prescribed Amount is not equal to INVOICEDAMOUNT\n",
    "df_final['Status'] = df_final.apply(lambda row: \"decline\" if row['Prescribed Amount'] != row['INVOICEDAMOUNT'] else \"proceed\", axis=1)\n",
    "\n",
    "# Step 13: Filter for final rows where status is \"proceed\" after the new condition\n",
    "df_final = df_final[df_final['Status'] == \"proceed\"]\n",
    "\n",
    "# Display the filtered dataframe\n",
    "print(df_final)\n",
    "\n",
    "# Optionally, save the final filtered data to a new CSV file\n",
    "df_final.to_csv('filtered_data_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa574f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 17, in <module>\n",
      "    from pandas.compat._constants import (\n",
      "ImportError: cannot import name 'ISMUSL' from 'pandas.compat._constants' (C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_constants.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Pathways\\AppData\\Local\\Temp\\ipykernel_13672\\2016072624.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 44, in <module>\n",
      "    raise ImportError(\n",
      "ImportError: C extension: pandas.compat._constants not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\Pathways\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Load datasets from CSV files\n",
    "df_new = pd.read_csv('new_data1.csv', low_memory=False)\n",
    "historical_data = pd.read_csv('historical_data1.csv', low_memory=False)\n",
    "\n",
    "# Preprocess historical_data\n",
    "historical_data = historical_data[['FIRSTDIAGNOSIS', 'ReasonText']].dropna()\n",
    "\n",
    "# Preprocess df_new\n",
    "df_new = df_new[['AUTHENTICATION_TYPE', 'POLICYSTATUS', 'FIRSTDIAGNOSIS', 'ReasonText', 'INVOICEDAMOUNT']]\n",
    "\n",
    "# Extract prescription names\n",
    "def extract_prescription_and_name(text):\n",
    "    if isinstance(text, str):\n",
    "        parts = text.rsplit(',', 2)\n",
    "        prescription = parts[-2].strip() if len(parts) > 1 else ''\n",
    "        match = re.search(r'^(.*?)\\s*\\(', prescription)\n",
    "        return match.group(1).strip() if match else prescription\n",
    "    return ''\n",
    "\n",
    "df_new['Prescription'] = df_new['ReasonText'].apply(extract_prescription_and_name)\n",
    "historical_data['Prescription'] = historical_data['ReasonText'].apply(extract_prescription_and_name)\n",
    "\n",
    "# Fill nulls in historical_data\n",
    "historical_data = historical_data.fillna(historical_data.mode().iloc[0])\n",
    "\n",
    "# Fill nulls in df_new\n",
    "df_new['INVOICEDAMOUNT'] = df_new['INVOICEDAMOUNT'].fillna(df_new['INVOICEDAMOUNT'].mean())\n",
    "df_new.fillna(df_new.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Filter POLICYSTATUS and AUTHENTICATION_TYPE\n",
    "df_new['Status'] = df_new['POLICYSTATUS'].apply(lambda x: \"proceed\" if x == \"Live\" else \"decline\")\n",
    "df_new = df_new[df_new['Status'] == \"proceed\"]\n",
    "df_new['Status'] = df_new['AUTHENTICATION_TYPE'].apply(lambda x: \"decline\" if x in [\"Blank\", \"UNAUTHORISED\", \"Off Smart\"] else \"proceed\")\n",
    "df_new = df_new[df_new['Status'] == \"proceed\"]\n",
    "\n",
    "# Fuzzy matching for prescriptions\n",
    "historical_dict = defaultdict(list)\n",
    "for diagnosis, prescription in zip(historical_data['FIRSTDIAGNOSIS'], historical_data['Prescription']):\n",
    "    historical_dict[diagnosis].append(prescription)\n",
    "\n",
    "def check_diagnosis_and_prescription(row, threshold=80):\n",
    "    diagnosis = row['FIRSTDIAGNOSIS']\n",
    "    prescription = row['Prescription']\n",
    "    if diagnosis in historical_dict:\n",
    "        max_score = max(fuzz.ratio(prescription, hist_prescription) for hist_prescription in historical_dict[diagnosis])\n",
    "        return \"proceed\" if max_score >= threshold else \"decline\"\n",
    "    return \"new diagnosis\"\n",
    "\n",
    "df_new['Status'] = df_new.apply(lambda row: check_diagnosis_and_prescription(row), axis=1)\n",
    "df_new = df_new[df_new['Status'] == \"proceed\"]\n",
    "\n",
    "# Compare Prescribed Amount and INVOICEDAMOUNT\n",
    "df_new['Prescribed Amount'] = df_new['ReasonText'].apply(lambda text: float(re.search(r'=(.*?)\\)', text).group(1).strip()) if isinstance(text, str) and re.search(r'=(.*?)\\)', text) else None)\n",
    "df_new['Status'] = df_new.apply(lambda row: \"decline\" if row['Prescribed Amount'] != row['INVOICEDAMOUNT'] else \"proceed\", axis=1)\n",
    "df_final = df_new[df_new['Status'] == \"proceed\"]\n",
    "\n",
    "# Save the filtered dataframe\n",
    "df_final.to_csv('filtered_data_set.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353cd3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def7b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534405f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af61e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2f9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a201df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ee7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217773c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ee812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd82f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1d678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae98280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract prescribed amounts\n",
    "if 'ReasonText' in df_new.columns:\n",
    "    df_new['Prescribed Amount'] = df_new['ReasonText'].apply(extract_prescribed_amount)\n",
    "\n",
    "# Filter based on INVOICELINEUSERSTATUS\n",
    "if 'INVOICELINEUSERSTATUS' in df_new.columns:\n",
    "    df_filtered = df_new[df_new['INVOICELINEUSERSTATUS'].isin(['Paid', 'NP - Not to be Paid'])]\n",
    "else:\n",
    "    df_filtered = df_new.copy()\n",
    "\n",
    "# Check POLICYSTATUS\n",
    "if 'POLICYSTATUS' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['POLICYSTATUS'].apply(lambda x: \"proceed\" if x == \"Live\" else \"decline\")\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "195b0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check AUTHENTICATION_TYPE\n",
    "def check_authentication(auth_type):\n",
    "    if auth_type in [\"Blank\", \"UNAUTHORISED\", \"Off Smart\"]:\n",
    "        return \"decline\"\n",
    "    return \"proceed\"\n",
    "\n",
    "if 'AUTHENTICATION_TYPE' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['AUTHENTICATION_TYPE'].apply(check_authentication)\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Create a dictionary for historical prescriptions\n",
    "historical_dict = defaultdict(list)\n",
    "if 'FIRSTDIAGNOSIS' in historical_data.columns and 'Prescription' in historical_data.columns:\n",
    "    for diagnosis, prescription in zip(historical_data['FIRSTDIAGNOSIS'], historical_data['Prescription']):\n",
    "        historical_dict[diagnosis].append(prescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check prescription match\n",
    "def check_diagnosis_and_prescription(row, historical_dict, threshold=80):\n",
    "    diagnosis = row['FIRSTDIAGNOSIS']\n",
    "    prescription = row['Prescription']\n",
    "    if diagnosis in historical_dict:\n",
    "        max_match_score = max(\n",
    "            (fuzz.ratio(prescription, hist_prescription) for hist_prescription in historical_dict[diagnosis]),\n",
    "            default=0,\n",
    "        )\n",
    "        return \"proceed\" if max_match_score >= threshold else \"decline\"\n",
    "    return \"new diagnosis\"\n",
    "\n",
    "df_filtered['Status'] = df_filtered.apply(\n",
    "    lambda row: check_diagnosis_and_prescription(row, historical_dict), axis=1\n",
    ")\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if Prescribed Amount matches INVOICEDAMOUNT\n",
    "if 'Prescribed Amount' in df_filtered.columns and 'INVOICEDAMOUNT' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered.apply(\n",
    "        lambda row: \"decline\" if row['Prescribed Amount'] != row['INVOICEDAMOUNT'] else \"proceed\", axis=1\n",
    "    )\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_data_set.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018f5684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [AUTHENTICATION_TYPE, POLICYSTATUS, FIRSTDIAGNOSIS, ReasonText, INVOICEDAMOUNT, Prescription, Prescribed Amount, Status]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Load datasets from CSV files with low_memory=False to prevent dtype warnings\n",
    "df_new = pd.read_csv('new_data.csv', low_memory=False)\n",
    "historical_data = pd.read_csv('historical_data.csv', low_memory=False)\n",
    "\n",
    "# For historical data: keep only 'FIRSTDIAGNOSIS' and 'ReasonText', drop nulls\n",
    "historical_data = historical_data[['FIRSTDIAGNOSIS', 'ReasonText']].dropna()\n",
    "\n",
    "# For df_new: keep only the specified columns\n",
    "df_new = df_new[['AUTHENTICATION_TYPE', 'POLICYSTATUS', 'FIRSTDIAGNOSIS', 'ReasonText', 'INVOICEDAMOUNT']]\n",
    "\n",
    "# Function to extract text between the last two commas\n",
    "def extract_prescription(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        parts = text.rsplit(',', 2)\n",
    "        if len(parts) > 1:\n",
    "            return parts[-2].strip()\n",
    "    return ''  # Default to empty string if not a string or insufficient parts\n",
    "\n",
    "# Function to extract prescription names\n",
    "def extract_prescription_name(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'^(.*?)\\s*\\(', text)  # Matches text before the first parenthesis\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned prescription name\n",
    "    return None  # Return None for invalid input\n",
    "\n",
    "# Apply extraction functions to both datasets\n",
    "for df in [historical_data, df_new]:\n",
    "    if 'ReasonText' in df.columns:\n",
    "        df['Prescription'] = df['ReasonText'].apply(extract_prescription)\n",
    "        df['Prescription Name'] = df['Prescription'].apply(extract_prescription_name)\n",
    "        df['Prescription'] = df['Prescription Name']\n",
    "        df.drop(columns=['Prescription Name'], inplace=True)\n",
    "\n",
    "# Function to extract prescribed amount\n",
    "def extract_prescribed_amount(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        match = re.search(r'=(.*?)\\)', text)\n",
    "        if match:\n",
    "            return match.group(1).strip()  # Return cleaned amount\n",
    "    return None  # Default to None for invalid input\n",
    "\n",
    "# Extract prescribed amounts\n",
    "if 'ReasonText' in df_new.columns:\n",
    "    df_new['Prescribed Amount'] = df_new['ReasonText'].apply(extract_prescribed_amount)\n",
    "\n",
    "# Filter based on INVOICELINEUSERSTATUS\n",
    "if 'INVOICELINEUSERSTATUS' in df_new.columns:\n",
    "    df_filtered = df_new[df_new['INVOICELINEUSERSTATUS'].isin(['Paid', 'NP - Not to be Paid'])]\n",
    "else:\n",
    "    df_filtered = df_new.copy()\n",
    "\n",
    "# Check POLICYSTATUS\n",
    "if 'POLICYSTATUS' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['POLICYSTATUS'].apply(lambda x: \"proceed\" if x == \"Live\" else \"decline\")\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Check AUTHENTICATION_TYPE\n",
    "def check_authentication(auth_type):\n",
    "    if auth_type in [\"Blank\", \"UNAUTHORISED\", \"Off Smart\"]:\n",
    "        return \"decline\"\n",
    "    return \"proceed\"\n",
    "\n",
    "if 'AUTHENTICATION_TYPE' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered['AUTHENTICATION_TYPE'].apply(check_authentication)\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Create a dictionary for historical prescriptions\n",
    "historical_dict = defaultdict(list)\n",
    "if 'FIRSTDIAGNOSIS' in historical_data.columns and 'Prescription' in historical_data.columns:\n",
    "    for diagnosis, prescription in zip(historical_data['FIRSTDIAGNOSIS'], historical_data['Prescription']):\n",
    "        historical_dict[diagnosis].append(prescription)\n",
    "\n",
    "# Function to check prescription match\n",
    "def check_diagnosis_and_prescription(row, historical_dict, threshold=80):\n",
    "    diagnosis = row['FIRSTDIAGNOSIS']\n",
    "    prescription = row['Prescription']\n",
    "    if diagnosis in historical_dict:\n",
    "        max_match_score = max(\n",
    "            (fuzz.ratio(prescription, hist_prescription) for hist_prescription in historical_dict[diagnosis]),\n",
    "            default=0,\n",
    "        )\n",
    "        return \"proceed\" if max_match_score >= threshold else \"decline\"\n",
    "    return \"new diagnosis\"\n",
    "\n",
    "df_filtered['Status'] = df_filtered.apply(\n",
    "    lambda row: check_diagnosis_and_prescription(row, historical_dict), axis=1\n",
    ")\n",
    "df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Check if Prescribed Amount matches INVOICEDAMOUNT\n",
    "if 'Prescribed Amount' in df_filtered.columns and 'INVOICEDAMOUNT' in df_filtered.columns:\n",
    "    df_filtered['Status'] = df_filtered.apply(\n",
    "        lambda row: \"decline\" if row['Prescribed Amount'] != row['INVOICEDAMOUNT'] else \"proceed\", axis=1\n",
    "    )\n",
    "    df_filtered = df_filtered[df_filtered['Status'] == \"proceed\"]\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_data_set.csv', index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134002e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
